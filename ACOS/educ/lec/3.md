АКОС #3 (16.09.2021)

Целочисленная арифметика

OFFTOP! Некая организация ФБК* (запрещённая в РФ) выложила довольно интересные списки на GitHub. РКН не дремлет, поэтому научитесь обходить блокировку!

***

Бывает полупроводимость, на ней основаны разные атомарные объекты a la резисторы, из которых состоят логические вентили, из которых устроен процессор и так далее...

Резистор, по сути, и есть кусочек полупроводника.

Самые примитивные элементы, реализуемые на кристалле: диод и так далее.

Есть два основных вида сигнала: аналоговые (используется в аудиоустройствах, например, в микрофонах) и дискретные.

В физике не бывает, что был сигнал и нет сигнала. Есть ещё и стандарт: 1.7 V < ... < 3.3 V - 1; 0 V < ... < 0.7 V - 0, между 0.7 V и 1.7 V состояние не определено.

Каждый логический вентиль имеет два входа и один выход. Распространена NAND-логика. Интересные картинки можно ещё раз посмотреть в презентации от Яковлева.

На самом деле, многие базовые функции выражаемы через другие. КНФ и ДНФ хорошо этому способствуют. Поэтому на базе более простых NAND-блоков можно строить более сложные NAND-блоки, например, NAND-блок, соответствующий xor.

Современные процессоры - маленькие кристаллы. Но так было не всегда! Сначала были компьютеры на лампах, довольно огромные, состоявшие из многих больших микросхем, на которых было лишь несколько логических вентилей. Часть нестандарного использования NAND-схем требует специальных лицензий от ФСБ в России (один из примеров был на слайде), без неё вы попадёте в ад... то есть, за решётку.

Ядро процессора поддерживает такие операции, как побитовые сдвиги, операции битовой логики, сложение/вычитание, умножение/деление. Есть специальные регистры, хранящие текущую позицию, и многое сводится к пересчёту.

Сумматор - устройство из двух блоков: блок исключющего "или" и блок, выводящий carry.

С неотрицательными числами хранение нехитрое. С отрицательными числами намного хитрее. Казалось бы, можно было бы хранить просто один бит под знак, но тут возникает много проблем. Во многих процессорах используется дополнительный код. Отрицательные числа нумеруются в обратном порядке, начиная со старшего бита. Операции сложения и вычитания тогда будут работать одинаково как с беззнаковыми, так и со знаковыми числами.

Пример: 3 + 10 = 13

  *
0 0 1 1
1 0 1 1
-------
1 1 0 1

Ещё один пример: 3 + (-6) = -3

  *
0 0 1 1
1 0 1 1
-------
1 1 0 1

Теперь не нужно реализовывать отдельное сложение и вычитание для отрицательных чисел!

Теперь о целочисленном переполнении. В случае unsigned просто берётся остаток по модулю. Если мы берём два числа, то сумма должна быть не меньше каждого из слагаемых. Если происходит переполнение, то сумма окажется меньше каждого из слагаемых. Это можно даже строго доказать.
А вот со знаковыми числами уже намного сложнее, так уже не работает. Тут уже много чего зависит от факторов. Например, integer overflow является UB с точки зрения стандартов C и C++.

Например, у нас есть программа, имеющая функцию bool some_function(int x), возвращающая (x + 1) > x, выводящая результат этой функции, а затем выводящая (INT_MAX + 1 > INT_MAX), написанная на Си. Без оптимизации вывод будет 1 и 0. Но существуют оптимизации, с которыми вывод будет 0 и 0.

Ситуацию может спасти санитайзер, который предупредит переполнение. Но есть и побочки, исходящие из того, что они представляют собой внешние функции. Кроме того, они очень зависимы от библиотек. К тому же программа работает медленно.

Довольно древний язык, как Pascal, довольно любим у учителей, потому что он работает довольно предсказуемо. В основу его положены те же идеи, которые есть у санитайзеров в C, что способствует предсказуемости, но снижает работоспособность программ.

К UB могут привести также поразрядные (побитовые) операции, которые безопасны для беззнаковых чисел, но довольно опасны для знаковых чисел. Например, при сдвиге знакового отрицательного вправо могут возникать проблемы из-за особенностей семантики, растягивающие беззнаковые отрицательные числа.

В 8-битном случае устроено просто - самый правый бит и есть самый младший. В 16-24-32-битных случаях всё сложнее, так как сами байты могут быть перемешаны.

Есть в C и C++ интересный тип union. Все поля, перечисленные в union, наслаиваются друг на друга. Поэтому этот факт можно использовать для нестандартного использования reinterpret_cast в обоих языках.

Для чего существует padding? Дело в том, что когда процессор может добраться до определённых полей, выгоднее прочитать весь регистр целиком. Иногда это бывает вредно.

Есть прикол! В Си размер пустой структуры - 0 байт! А вот в С++ уже 1 байт. Просто в C++ немного другой уровень абстракции, и стандартом гарантируется, что разные переменные имеют разные адреса, иначе была бы ситуация, о которой Илья Мещерин рассказывал на своих лекциях.

С целыми числами всё понятно. Но что происходит с числами с плавающей точкой, которые предназначены для арифметики с произвольной точностью? Есть числа с одинарной точностью, которые сегодня используются разве что в видеокартах. Есть числа с двойной точностью.
Сначала идёт бит, отвечающий за знак, затем идёт экспоненциальная часть, затем идёт мантисса.
Как выполняются операции с такими числами? Чтобы умножить два числа, нужно отдельно посчитать знак, сложить экспоненциональную часть, затем перемножить мантиссы, затем нормализировать мантиссу. Сложение довольно сложное. 

Только в начале 90-х, начиная с 486-го процессора, математический блок встроен в процессор. До 386-го включительно математический сопроцессор продавался отдельно, и не все программы его использовали. Но до сих пор с целью совместимости поддерживается семантика 387-го сопроцессора.

Есть несколько вырожденных случаев. Пусть мантисса состоит из всех нулей. Рассмотрим остальные разряды. Если все разряды нули, то это строго ноль. Если старший бит - единица, а все остальные нули, то это отрицательный нуль. Если все разряды единицы, кроме старшего бита, то это +\infty. Если вообще все разряды единицы, то это -\infty. Если же мантисса ненулевая, то там уже интереснее (подробнее в презентации Яковлева).

Интересный факт! В JavaScript число занимает 53 бита! Один на знак, остальные на мантиссу. Там вообще нет деления на целые числа и числа с плавающей точкой.

тип данных - не панацея. Примерно после 6-7-го знака после запятой начинаются неточные вещи, которые в диффурах и на АЭС крайне критичны. Кроме того, в экономике это тоже может привести к некоторым проблемам, особенно с инвесторами.

Как работают числа с фиксированной точкой? Здесь банковский подход: округление зависит от чётности чисел. Это помогает компенсировать погрешности.
